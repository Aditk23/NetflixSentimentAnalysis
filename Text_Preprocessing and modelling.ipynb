{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f98d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2395c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset for postitve and negative review\n",
    "\n",
    "pos_review = pd.read_csv('pos.txt',encoding='latin-1',header=None,sep='\\n')\n",
    "pos_review['sentiment']=1\n",
    "pos_review.rename(columns={0:'review'},inplace=True)\n",
    "neg_review = pd.read_csv('negative.txt',encoding='latin-1',header=None,sep='\\n')\n",
    "neg_review['sentiment']=0\n",
    "neg_review.rename(columns={0:'review'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838f3597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>both exuberantly romantic and serenely melanch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>mazel tov to a film about a family's joyous li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>standing in the shadows of motown is the best ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>it's nice to see piscopo again after all these...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>provides a porthole into that noble , tremblin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     the rock is destined to be the 21st century's ...          1\n",
       "1     the gorgeously elaborate continuation of \" the...          1\n",
       "2                        effective but too-tepid biopic          1\n",
       "3     if you sometimes like to go to the movies to h...          1\n",
       "4     emerges as something rare , an issue movie tha...          1\n",
       "...                                                 ...        ...\n",
       "5326  both exuberantly romantic and serenely melanch...          1\n",
       "5327  mazel tov to a film about a family's joyous li...          1\n",
       "5328  standing in the shadows of motown is the best ...          1\n",
       "5329  it's nice to see piscopo again after all these...          1\n",
       "5330  provides a porthole into that noble , tremblin...          1\n",
       "\n",
       "[5331 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d72d423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simplistic , silly and tedious.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's so laddish and juvenile , only teenage bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exploitative and largely devoid of the depth o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[garbus] discards the potential for pathologic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a visually flashy but narratively opaque and e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>a terrible movie that some people will neverth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>there are many definitions of 'time waster' bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>as it stands , crocodile hunter has the hurrie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>the thing looks like a made-for-home-video qui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>enigma is well-made , but it's just too dry an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0                      simplistic , silly and tedious.           0\n",
       "1     it's so laddish and juvenile , only teenage bo...          0\n",
       "2     exploitative and largely devoid of the depth o...          0\n",
       "3     [garbus] discards the potential for pathologic...          0\n",
       "4     a visually flashy but narratively opaque and e...          0\n",
       "...                                                 ...        ...\n",
       "5326  a terrible movie that some people will neverth...          0\n",
       "5327  there are many definitions of 'time waster' bu...          0\n",
       "5328  as it stands , crocodile hunter has the hurrie...          0\n",
       "5329  the thing looks like a made-for-home-video qui...          0\n",
       "5330  enigma is well-made , but it's just too dry an...          0\n",
       "\n",
       "[5331 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c310762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  the rock is destined to be the 21st century's ...          1\n",
       "1  the gorgeously elaborate continuation of \" the...          1\n",
       "2                     effective but too-tepid biopic          1\n",
       "3  if you sometimes like to go to the movies to h...          1\n",
       "4  emerges as something rare , an issue movie tha...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([pos_review,neg_review],axis=0,ignore_index=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4340868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>a terrible movie that some people will neverth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>there are many definitions of 'time waster' bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>as it stands , crocodile hunter has the hurrie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>the thing looks like a made-for-home-video qui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>enigma is well-made , but it's just too dry an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "10657  a terrible movie that some people will neverth...          0\n",
       "10658  there are many definitions of 'time waster' bu...          0\n",
       "10659  as it stands , crocodile hunter has the hurrie...          0\n",
       "10660  the thing looks like a made-for-home-video qui...          0\n",
       "10661  enigma is well-made , but it's just too dry an...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e81e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  the rock is destined to be the 21st century's ...\n",
       "1  the gorgeously elaborate continuation of \" the...\n",
       "2                     effective but too-tepid biopic\n",
       "3  if you sometimes like to go to the movies to h...\n",
       "4  emerges as something rare , an issue movie tha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = all_data[['review']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bdc12",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161e1b3",
   "metadata": {},
   "source": [
    "### Converting text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6855ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  the rock is destined to be the 21st century's ...  \n",
       "1  the gorgeously elaborate continuation of \" the...  \n",
       "2                     effective but too-tepid biopic  \n",
       "3  if you sometimes like to go to the movies to h...  \n",
       "4  emerges as something rare , an issue movie tha...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_lower\"] = df[\"review\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a84b6",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3b2e2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Adit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00987db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all stopwords in nltk library\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b02ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  rock destined 21st century's new \" conan \" he'...  \n",
       "1  gorgeously elaborate continuation \" lord rings...  \n",
       "2                         effective too-tepid biopic  \n",
       "3  sometimes like go movies fun , wasabi good pla...  \n",
       "4  emerges something rare , issue movie that's ho...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_lower\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38381c97",
   "metadata": {},
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fdac716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "print (PUNCT_TO_REMOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1744358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "      <td>rock destined 21st centurys new  conan  hes go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "      <td>gorgeously elaborate continuation  lord rings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "      <td>sometimes like go movies fun  wasabi good plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "      <td>emerges something rare  issue movie thats hone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  rock destined 21st century's new \" conan \" he'...   \n",
       "1  gorgeously elaborate continuation \" lord rings...   \n",
       "2                         effective too-tepid biopic   \n",
       "3  sometimes like go movies fun , wasabi good pla...   \n",
       "4  emerges something rare , issue movie that's ho...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  rock destined 21st centurys new  conan  hes go...  \n",
       "1  gorgeously elaborate continuation  lord rings ...  \n",
       "2                          effective tootepid biopic  \n",
       "3  sometimes like go movies fun  wasabi good plac...  \n",
       "4  emerges something rare  issue movie thats hone...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"text_wo_stop\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cffb9a",
   "metadata": {},
   "source": [
    "### Removing rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c582ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 1453),\n",
       " ('movie', 1270),\n",
       " ('one', 727),\n",
       " ('like', 721),\n",
       " ('story', 477),\n",
       " ('much', 386),\n",
       " ('even', 382),\n",
       " ('good', 377),\n",
       " ('comedy', 359),\n",
       " ('time', 341)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_wo_punct\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "# Printing 10 most common words        \n",
    "cnt.most_common(10)\n",
    "\n",
    "# Some of these words such as like,good are essential for sentiment analysis hence not removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c639f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pamelas', 'chore', 'waster', 'rodan', 'discount', 'principle', 'definitions', 'madeforhomevideo', 'stevenons', 'dozing', 'uncertainty', 'startled', 'juliet', 'commenting', 'agile', 'roller', 'hurried', 'shouting', 'coaster', '1959'}\n"
     ]
    }
   ],
   "source": [
    "# Printing 20 most rare words\n",
    "n_rare_words = 20\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "print(RAREWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40b2cf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "      <td>rock destined 21st centurys new  conan  hes go...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "      <td>gorgeously elaborate continuation  lord rings ...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "      <td>sometimes like go movies fun  wasabi good plac...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "      <td>emerges something rare  issue movie thats hone...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  rock destined 21st century's new \" conan \" he'...   \n",
       "1  gorgeously elaborate continuation \" lord rings...   \n",
       "2                         effective too-tepid biopic   \n",
       "3  sometimes like go movies fun , wasabi good pla...   \n",
       "4  emerges something rare , issue movie that's ho...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  rock destined 21st centurys new  conan  hes go...   \n",
       "1  gorgeously elaborate continuation  lord rings ...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun  wasabi good plac...   \n",
       "4  emerges something rare  issue movie thats hone...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \n",
       "0  rock destined 21st centurys new conan hes goin...  \n",
       "1  gorgeously elaborate continuation lord rings t...  \n",
       "2                          effective tootepid biopic  \n",
       "3  sometimes like go movies fun wasabi good place...  \n",
       "4  emerges something rare issue movie thats hones...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "df[\"text_wo_stopfreqrare\"] = df[\"text_wo_punct\"].apply(lambda text: remove_rarewords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb7511",
   "metadata": {},
   "source": [
    "### Removing digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e0ac674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "      <th>text_wo_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "      <td>rock destined 21st centurys new  conan  hes go...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "      <td>gorgeously elaborate continuation  lord rings ...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "      <td>sometimes like go movies fun  wasabi good plac...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "      <td>emerges something rare  issue movie thats hone...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  rock destined 21st century's new \" conan \" he'...   \n",
       "1  gorgeously elaborate continuation \" lord rings...   \n",
       "2                         effective too-tepid biopic   \n",
       "3  sometimes like go movies fun , wasabi good pla...   \n",
       "4  emerges something rare , issue movie that's ho...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  rock destined 21st centurys new  conan  hes go...   \n",
       "1  gorgeously elaborate continuation  lord rings ...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun  wasabi good plac...   \n",
       "4  emerges something rare  issue movie thats hone...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \\\n",
       "0  rock destined 21st centurys new conan hes goin...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                                      text_wo_digits  \n",
       "0  rock destined 21st centurys new conan hes goin...  \n",
       "1  gorgeously elaborate continuation lord rings t...  \n",
       "2                          effective tootepid biopic  \n",
       "3  sometimes like go movies fun wasabi good place...  \n",
       "4  emerges something rare issue movie thats hones...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_digits(text):\n",
    "    \"\"\"function to remove digits\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if not word.isdigit()])\n",
    "\n",
    "\n",
    "df[\"text_wo_digits\"] = df[\"text_wo_stopfreqrare\"].apply(lambda text: remove_digits(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "002bd005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        rock destined  centurys new conan hes going ma...\n",
       "1        rock destined  centurys new conan hes going ma...\n",
       "2        rock destined  centurys new conan hes going ma...\n",
       "3        rock destined  centurys new conan hes going ma...\n",
       "4        rock destined  centurys new conan hes going ma...\n",
       "                               ...                        \n",
       "10657    rock destined  centurys new conan hes going ma...\n",
       "10658    rock destined  centurys new conan hes going ma...\n",
       "10659    rock destined  centurys new conan hes going ma...\n",
       "10660    rock destined  centurys new conan hes going ma...\n",
       "10661    rock destined  centurys new conan hes going ma...\n",
       "Name: text_wo_digits, Length: 10662, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "lst=[]\n",
    "def remove_special_digits(text):\n",
    "    pattern = r'[0-9]+[a-zA-Z]+'\n",
    "    for word in str(text).split(): \n",
    "        new_string = re.sub(pattern, '', word)\n",
    "        lst.append(new_string)\n",
    "    return \" \".join(lst)\n",
    "df2 = df['text_wo_digits'].apply(lambda text: remove_special_digits(text))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b255afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "      <th>text_wo_digits</th>\n",
       "      <th>text_wo_special_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "      <td>rock destined 21st centurys new  conan  hes go...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "      <td>rock destined centurys new conan hes going mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "      <td>gorgeously elaborate continuation  lord rings ...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "      <td>sometimes like go movies fun  wasabi good plac...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "      <td>emerges something rare  issue movie thats hone...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  rock destined 21st century's new \" conan \" he'...   \n",
       "1  gorgeously elaborate continuation \" lord rings...   \n",
       "2                         effective too-tepid biopic   \n",
       "3  sometimes like go movies fun , wasabi good pla...   \n",
       "4  emerges something rare , issue movie that's ho...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  rock destined 21st centurys new  conan  hes go...   \n",
       "1  gorgeously elaborate continuation  lord rings ...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun  wasabi good plac...   \n",
       "4  emerges something rare  issue movie thats hone...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \\\n",
       "0  rock destined 21st centurys new conan hes goin...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                                      text_wo_digits  \\\n",
       "0  rock destined 21st centurys new conan hes goin...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                              text_wo_special_digits  \n",
       "0  rock destined centurys new conan hes going mak...  \n",
       "1  gorgeously elaborate continuation lord rings t...  \n",
       "2                          effective tootepid biopic  \n",
       "3  sometimes like go movies fun wasabi good place...  \n",
       "4  emerges something rare issue movie thats hones...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some numbers liks 1990s or 3rd , removing those as well\n",
    "pattern = r'[0-9]+[a-zA-Z]+'\n",
    "def remove_special_digits(text):\n",
    "    return \" \".join([word for word in str(text).split() if len(re.sub(pattern, '', word))>0])\n",
    "    \n",
    "df['text_wo_special_digits'] = df['text_wo_digits'].apply(lambda text: remove_special_digits(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3316793",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e93672c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Adit/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5d625e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "      <th>text_wo_digits</th>\n",
       "      <th>text_wo_special_digits</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>rock destined 21st century's new \" conan \" he'...</td>\n",
       "      <td>rock destined 21st centurys new  conan  hes go...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "      <td>rock destined 21st centurys new conan hes goin...</td>\n",
       "      <td>rock destined centurys new conan hes going mak...</td>\n",
       "      <td>rock destine centurys new conan he go make spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>gorgeously elaborate continuation \" lord rings...</td>\n",
       "      <td>gorgeously elaborate continuation  lord rings ...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord rings t...</td>\n",
       "      <td>gorgeously elaborate continuation lord ring tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>effective too-tepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "      <td>effective tootepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>sometimes like go movies fun , wasabi good pla...</td>\n",
       "      <td>sometimes like go movies fun  wasabi good plac...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movies fun wasabi good place...</td>\n",
       "      <td>sometimes like go movie fun wasabi good place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>emerges something rare , issue movie that's ho...</td>\n",
       "      <td>emerges something rare  issue movie thats hone...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "      <td>emerges something rare issue movie thats hones...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  the rock is destined to be the 21st century's ...   \n",
       "1  the gorgeously elaborate continuation of \" the...   \n",
       "2                     effective but too-tepid biopic   \n",
       "3  if you sometimes like to go to the movies to h...   \n",
       "4  emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  rock destined 21st century's new \" conan \" he'...   \n",
       "1  gorgeously elaborate continuation \" lord rings...   \n",
       "2                         effective too-tepid biopic   \n",
       "3  sometimes like go movies fun , wasabi good pla...   \n",
       "4  emerges something rare , issue movie that's ho...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  rock destined 21st centurys new  conan  hes go...   \n",
       "1  gorgeously elaborate continuation  lord rings ...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun  wasabi good plac...   \n",
       "4  emerges something rare  issue movie thats hone...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \\\n",
       "0  rock destined 21st centurys new conan hes goin...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                                      text_wo_digits  \\\n",
       "0  rock destined 21st centurys new conan hes goin...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                              text_wo_special_digits  \\\n",
       "0  rock destined centurys new conan hes going mak...   \n",
       "1  gorgeously elaborate continuation lord rings t...   \n",
       "2                          effective tootepid biopic   \n",
       "3  sometimes like go movies fun wasabi good place...   \n",
       "4  emerges something rare issue movie thats hones...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  rock destine centurys new conan he go make spl...  \n",
       "1  gorgeously elaborate continuation lord ring tr...  \n",
       "2                          effective tootepid biopic  \n",
       "3  sometimes like go movie fun wasabi good place ...  \n",
       "4  emerges something rare issue movie thats hones...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "def lemmatize_words(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text_wo_special_digits\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b15a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df['text_lemmatized'].values,all_data['sentiment'].values,test_size=0.2,random_state=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68b067c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({'review':X_train , 'sentiment':y_train})\n",
    "test_data = pd.DataFrame({'review':X_test , 'sentiment':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e63798e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie amateurish minor treat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unfortunately heartbreak hospital want convey ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australia land beyond time enjoyable big movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr deed sure give lot laugh simple sweet roman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sort burly action flick one coincidence pummel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>whats next rob schneider dana carvey sarah mic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>result something quite fresh delightful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>despite hoffman best effort wilson remain sile...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>unusually dryeyed even analytical approach mat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>stand haunt it punk rock music use video mediu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8529 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0                          movie amateurish minor treat          1\n",
       "1     unfortunately heartbreak hospital want convey ...          0\n",
       "2     australia land beyond time enjoyable big movie...          1\n",
       "3     mr deed sure give lot laugh simple sweet roman...          1\n",
       "4     sort burly action flick one coincidence pummel...          0\n",
       "...                                                 ...        ...\n",
       "8524  whats next rob schneider dana carvey sarah mic...          0\n",
       "8525            result something quite fresh delightful          1\n",
       "8526  despite hoffman best effort wilson remain sile...          0\n",
       "8527  unusually dryeyed even analytical approach mat...          1\n",
       "8528  stand haunt it punk rock music use video mediu...          1\n",
       "\n",
       "[8529 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5c4fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whats surprising traditional thriller moderate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three excellent principal singer youthful good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie feel like pilot episode new teentargeted...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cast delivers without sham rawnerved story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stagey talky long good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>unsurprisingly way work make woman look like s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>friday next kind film could make africanameric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>humble little film fuel light comedic work zha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>story intelligent high school student deal fir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>even would like dismiss film outright find muc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     whats surprising traditional thriller moderate...          0\n",
       "1     three excellent principal singer youthful good...          1\n",
       "2     movie feel like pilot episode new teentargeted...          0\n",
       "3            cast delivers without sham rawnerved story          1\n",
       "4                                stagey talky long good          0\n",
       "...                                                 ...        ...\n",
       "2128  unsurprisingly way work make woman look like s...          0\n",
       "2129  friday next kind film could make africanameric...          0\n",
       "2130  humble little film fuel light comedic work zha...          1\n",
       "2131  story intelligent high school student deal fir...          1\n",
       "2132  even would like dismiss film outright find muc...          1\n",
       "\n",
       "[2133 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44a1f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_data['review'])\n",
    "test_vectors = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a05a3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70s',\n",
       " 'aaliyah',\n",
       " 'aan',\n",
       " 'abagnales',\n",
       " 'abandon',\n",
       " 'abandone',\n",
       " 'abbass',\n",
       " 'abbasss',\n",
       " 'abbott',\n",
       " 'abbreviate',\n",
       " 'abc',\n",
       " 'abderrahmane',\n",
       " 'abel',\n",
       " 'aberration',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abide',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'abornin',\n",
       " 'abort',\n",
       " 'aboul',\n",
       " 'abound',\n",
       " 'aboveaverage',\n",
       " 'abrasive',\n",
       " 'abridge',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolutamente',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbs',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'aby',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'acaba',\n",
       " 'acabamos',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'accelerated',\n",
       " 'accent',\n",
       " 'accentuate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentprone',\n",
       " 'acclaim',\n",
       " 'accommodate',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'accordionharmonicabanjo',\n",
       " 'accorsi',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'ace',\n",
       " 'aceitou',\n",
       " 'acerbic',\n",
       " 'acerta',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achilles',\n",
       " 'achingly',\n",
       " 'achival',\n",
       " 'achronological',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledges',\n",
       " 'acolyte',\n",
       " 'acontecimentos',\n",
       " 'acquaint',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acre',\n",
       " 'acrid',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'actingworkshop',\n",
       " 'action',\n",
       " 'actionadventure',\n",
       " 'actioncomedy',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actionfantasy',\n",
       " 'actionmovie',\n",
       " 'actionoriented',\n",
       " 'actionpacked',\n",
       " 'actionthriller',\n",
       " 'actionthrillerdark',\n",
       " 'activate',\n",
       " 'activism',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actordirector',\n",
       " 'actores',\n",
       " 'actorish',\n",
       " 'actorliness',\n",
       " 'actorly',\n",
       " 'actory',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actuaciones',\n",
       " 'actuada',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actuary',\n",
       " 'acumen',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adicional',\n",
       " 'adjective',\n",
       " 'adjust',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'ado',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'aerial',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'affability',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affectationfree',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'afflict',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affords',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'africanamericans',\n",
       " 'after',\n",
       " 'afterhours',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'againcourage',\n",
       " 'agape',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agesa',\n",
       " 'agesold',\n",
       " 'agewise',\n",
       " 'aggrandize',\n",
       " 'aggravate',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'aggrieved',\n",
       " 'agitprop',\n",
       " 'agnostic',\n",
       " 'ago',\n",
       " 'agonize',\n",
       " 'agony',\n",
       " 'agradecido',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreeably',\n",
       " 'agreement',\n",
       " 'aground',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahhhh',\n",
       " 'ahnulds',\n",
       " 'ahola',\n",
       " 'aholas',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aiello',\n",
       " 'aim',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aimlessness',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airless',\n",
       " 'airport',\n",
       " 'airtime',\n",
       " 'airy',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'akasha',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'aknocking',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alacrity',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmingly',\n",
       " 'alas',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'alcatraz',\n",
       " 'alchemical',\n",
       " 'alchemy',\n",
       " 'alcoholic',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'algún',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alices',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienation',\n",
       " 'alike',\n",
       " 'alis',\n",
       " 'alist',\n",
       " 'alive',\n",
       " 'allages',\n",
       " 'allaround',\n",
       " 'allege',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allegorical',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allens',\n",
       " 'allenveloping',\n",
       " 'allergy',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'allinall',\n",
       " 'allinclusive',\n",
       " 'allison',\n",
       " 'allmale',\n",
       " 'allnight',\n",
       " 'allodi',\n",
       " 'allout',\n",
       " 'alloverthemap',\n",
       " 'allow',\n",
       " 'allpowerful',\n",
       " 'alls',\n",
       " 'allstar',\n",
       " 'allstars',\n",
       " 'alltime',\n",
       " 'alltoofamiliar',\n",
       " 'alltoohuman',\n",
       " 'allure',\n",
       " 'allusion',\n",
       " 'allwoman',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almodovar',\n",
       " 'almodóvar',\n",
       " 'almost',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'aloof',\n",
       " 'alpha',\n",
       " 'already',\n",
       " 'alreadyshallow',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altmanesque',\n",
       " 'altmans',\n",
       " 'altogether',\n",
       " 'alvo',\n",
       " 'always',\n",
       " 'alzheimers',\n",
       " 'amalgam',\n",
       " 'amalgamate',\n",
       " 'amaro',\n",
       " 'amass',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amateurishness',\n",
       " 'amaze',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amber',\n",
       " 'ambience',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambition133',\n",
       " 'ambitious',\n",
       " 'ambitiously',\n",
       " 'amble',\n",
       " 'ambrose',\n",
       " 'amc',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americanrussian',\n",
       " 'americans',\n",
       " 'americanstyle',\n",
       " 'americas',\n",
       " 'amiability',\n",
       " 'amiable',\n",
       " 'amiably',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amini',\n",
       " 'amir',\n",
       " 'amish',\n",
       " 'amistad',\n",
       " 'amnesiac',\n",
       " 'amok',\n",
       " 'among',\n",
       " 'amor',\n",
       " 'amoral',\n",
       " 'amorality',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amour',\n",
       " 'ampedup',\n",
       " 'ample',\n",
       " 'amradio',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusedly',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'amys',\n",
       " 'amélie',\n",
       " 'amélies',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anachronistic',\n",
       " 'analgesic',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'anarchic',\n",
       " 'anarchist',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'anas',\n",
       " 'anatomical',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anciently',\n",
       " 'ancillary',\n",
       " 'and',\n",
       " 'andamento',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'anderssons',\n",
       " 'andie',\n",
       " 'andmiss',\n",
       " 'andor',\n",
       " 'andrei',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andré',\n",
       " 'andy',\n",
       " 'andys',\n",
       " 'anemic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angelique',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angstridden',\n",
       " 'anguish',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animatedmovie',\n",
       " 'animation',\n",
       " 'animaton',\n",
       " 'animator',\n",
       " 'animatronic',\n",
       " 'anime',\n",
       " 'animé',\n",
       " 'aniston',\n",
       " 'ankledeep',\n",
       " 'anna',\n",
       " 'annals',\n",
       " 'anne',\n",
       " 'annesophie',\n",
       " 'annex',\n",
       " 'annie',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'anomaly',\n",
       " 'anomie',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'anothers',\n",
       " 'anspaughs',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'ante',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthropologically',\n",
       " 'anthropology',\n",
       " 'anthropomorphic',\n",
       " 'anti',\n",
       " 'antiadult',\n",
       " 'antic',\n",
       " 'anticatholic',\n",
       " 'anticipate',\n",
       " 'anticipation',\n",
       " 'antidarwinian',\n",
       " 'antidate',\n",
       " 'antidote',\n",
       " 'antierotic',\n",
       " 'antiestablishment',\n",
       " 'antifeminist',\n",
       " 'antiharry',\n",
       " 'antihollywood',\n",
       " 'antikieslowski',\n",
       " 'antique',\n",
       " 'antisemitism',\n",
       " 'antiseptic',\n",
       " 'antitrust',\n",
       " 'antivirus',\n",
       " 'antiwar',\n",
       " 'anton',\n",
       " 'antonia',\n",
       " 'antonias',\n",
       " 'antonio',\n",
       " 'antsy',\n",
       " 'antwone',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'ao',\n",
       " 'apallingly',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apenas',\n",
       " 'apesar',\n",
       " 'apex',\n",
       " 'aplenty',\n",
       " 'aplomb',\n",
       " 'apocalypse',\n",
       " 'apolitical',\n",
       " 'apollo',\n",
       " 'apology',\n",
       " 'appal',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealingly',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appetite',\n",
       " 'appetizer',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applegate',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appraisal',\n",
       " 'appreciate',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehension',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approximation',\n",
       " 'appétit',\n",
       " 'april',\n",
       " 'aprovechar',\n",
       " 'aproveitar',\n",
       " 'apt',\n",
       " 'apted',\n",
       " 'aptly',\n",
       " 'apuestas',\n",
       " 'aquatic',\n",
       " 'aquel',\n",
       " 'aqueles',\n",
       " 'aragorns',\n",
       " 'ararat',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'arcanum',\n",
       " 'arch',\n",
       " 'archetypal',\n",
       " 'archibald',\n",
       " 'architect',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'archival',\n",
       " 'archive',\n",
       " 'archly',\n",
       " 'arctic',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'arduous',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'argentine',\n",
       " 'argento',\n",
       " 'argentos',\n",
       " 'argot',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'argumentação',\n",
       " 'arise',\n",
       " 'aristocracy',\n",
       " 'aristocrat',\n",
       " 'aristocratic',\n",
       " 'arithmetic',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arkin',\n",
       " 'arliss',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armchair',\n",
       " 'armenian',\n",
       " 'army',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arouse',\n",
       " 'arquette',\n",
       " 'arrancar',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arresting',\n",
       " 'arriesgado',\n",
       " 'arrive',\n",
       " 'arrives',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'artdirected',\n",
       " 'artefact',\n",
       " 'arteta',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'arthouse',\n",
       " 'arthur',\n",
       " 'articulate',\n",
       " 'artifact',\n",
       " 'artifice',\n",
       " 'artificial',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artiste',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artless',\n",
       " 'artsploitation',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'artístico',\n",
       " 'arwen',\n",
       " 'asbury',\n",
       " 'ascend',\n",
       " 'ascension',\n",
       " 'ascertain',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ashtray',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiaphiles',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'asit',\n",
       " 'ask',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asnasty',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspiration',\n",
       " 'aspire',\n",
       " 'aspires',\n",
       " 'asquiths',\n",
       " 'assailant',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assaultive',\n",
       " 'assayas',\n",
       " 'assemble',\n",
       " 'assembles',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'assertive',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assimilate',\n",
       " 'assistant',\n",
       " 'assistir',\n",
       " 'associate',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'assuredly',\n",
       " 'assuredness',\n",
       " 'astonish',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astoria',\n",
       " 'astound',\n",
       " 'astoundingly',\n",
       " 'astounds',\n",
       " 'astray',\n",
       " 'astringent',\n",
       " 'astronaut',\n",
       " 'astronomically',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'at',\n",
       " 'atacar',\n",
       " 'atacarse',\n",
       " 'atafratparty',\n",
       " 'atavistic',\n",
       " 'ate',\n",
       " 'ateam',\n",
       " 'atheistic',\n",
       " 'athlete',\n",
       " 'athletes',\n",
       " 'athletic',\n",
       " 'athleticism',\n",
       " 'atlantic',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherics',\n",
       " 'atom',\n",
       " 'atonal',\n",
       " 'atop',\n",
       " 'atreve',\n",
       " 'atrocious',\n",
       " 'atrociously',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacker',\n",
       " 'attal',\n",
       " 'attals',\n",
       " 'attempt',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attributable',\n",
       " 'attune',\n",
       " 'atypically',\n",
       " 'audacious',\n",
       " 'audaciousimpossible',\n",
       " 'audacity',\n",
       " 'audiards',\n",
       " 'audience',\n",
       " 'audienceabuse',\n",
       " 'audienceas',\n",
       " 'audiencepleaser',\n",
       " 'audio',\n",
       " 'auditorium',\n",
       " 'audrey',\n",
       " 'augment',\n",
       " 'augmentation',\n",
       " 'august',\n",
       " 'augustine',\n",
       " 'aunque',\n",
       " 'aura',\n",
       " 'aurelie',\n",
       " 'auschwitz',\n",
       " 'auspicious',\n",
       " 'austen',\n",
       " 'austenand',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'australias',\n",
       " 'austrian',\n",
       " 'auteil',\n",
       " 'auteils',\n",
       " 'auteuil',\n",
       " 'auteuils',\n",
       " 'auteur',\n",
       " 'auteurs',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticate',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autobiographical',\n",
       " 'automate',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'autopsy',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avant',\n",
       " 'avantgarde',\n",
       " 'avarice',\n",
       " 'avary',\n",
       " 'avarys',\n",
       " 'avenge',\n",
       " 'avenger',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'averse',\n",
       " 'aversion',\n",
       " 'avert',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avoids',\n",
       " 'avon',\n",
       " 'avuncular',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'awakening',\n",
       " 'awakens',\n",
       " 'award',\n",
       " 'awardswith',\n",
       " 'awardwinning',\n",
       " 'awardworthy',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awash',\n",
       " 'away',\n",
       " 'awaystill',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'aweinspiring',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfulness',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'awry',\n",
       " 'axel',\n",
       " 'axis',\n",
       " 'ayala',\n",
       " 'ayatollah',\n",
       " 'ayurveda',\n",
       " 'b12',\n",
       " 'ba',\n",
       " 'baaaaaaaaad',\n",
       " 'babak',\n",
       " 'babbitt',\n",
       " 'babe',\n",
       " 'baboon',\n",
       " 'baby',\n",
       " 'babyfaced',\n",
       " 'babysitter',\n",
       " 'bacaasay',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backdrop',\n",
       " 'background',\n",
       " 'backhand',\n",
       " 'backhanded',\n",
       " 'backlash',\n",
       " 'backmasking',\n",
       " 'backroom',\n",
       " 'backseat',\n",
       " 'backstabbing',\n",
       " 'backstage',\n",
       " 'backstory',\n",
       " 'backward',\n",
       " 'backwater',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'badboy',\n",
       " 'badder',\n",
       " 'badluck',\n",
       " 'badly',\n",
       " 'badlyrendered',\n",
       " 'badmovie',\n",
       " 'badness',\n",
       " 'baffle',\n",
       " 'baffling',\n",
       " 'bag',\n",
       " 'bagatelle',\n",
       " 'baggage',\n",
       " 'bai',\n",
       " 'bailiwick',\n",
       " 'bailly',\n",
       " 'baillys',\n",
       " 'baio',\n",
       " 'baird',\n",
       " 'baitandtackle',\n",
       " 'baja',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'balance',\n",
       " 'bald',\n",
       " 'bale',\n",
       " 'balk',\n",
       " 'balkan',\n",
       " 'ball',\n",
       " 'ballandchain',\n",
       " 'ballerina',\n",
       " 'ballet',\n",
       " 'balletic',\n",
       " 'ballhaus',\n",
       " 'ballistic',\n",
       " 'ballisticpyrotechnic',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'ballplayer',\n",
       " 'ballpoint',\n",
       " 'ballroom',\n",
       " 'balm',\n",
       " 'baloney',\n",
       " 'balto',\n",
       " 'banal',\n",
       " 'banales',\n",
       " 'banality',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a38da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b9659ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc.predict(test_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48405805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1072\n",
      "           1       0.75      0.75      0.75      1061\n",
      "\n",
      "    accuracy                           0.75      2133\n",
      "   macro avg       0.75      0.75      0.75      2133\n",
      "weighted avg       0.75      0.75      0.75      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['sentiment'],pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73ff85ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 0.7502356267672008\n",
      "Negative 0.7509328358208955\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positive {report['1']['recall']}\")\n",
    "print(f\"Negative {report['0']['recall']}\")\n",
    "\n",
    "# 75% recall with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc11df6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7523364485981309,\n",
       "  'recall': 0.7509328358208955,\n",
       "  'f1-score': 0.7516339869281045,\n",
       "  'support': 1072},\n",
       " '1': {'precision': 0.748824082784572,\n",
       "  'recall': 0.7502356267672008,\n",
       "  'f1-score': 0.7495291902071564,\n",
       "  'support': 1061},\n",
       " 'accuracy': 0.7505860290670417,\n",
       " 'macro avg': {'precision': 0.7505802656913514,\n",
       "  'recall': 0.7505842312940482,\n",
       "  'f1-score': 0.7505815885676304,\n",
       "  'support': 2133},\n",
       " 'weighted avg': {'precision': 0.7505893224245791,\n",
       "  'recall': 0.7505860290670417,\n",
       "  'f1-score': 0.7505870158446887,\n",
       "  'support': 2133}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c6f2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Good movie']\n",
    "vector = vectorizer.transform(data).toarray()\n",
    "prediction = classifier.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "932e9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good review\n"
     ]
    }
   ],
   "source": [
    "if(prediction[0]==1):\n",
    "    print('Good review')\n",
    "else:\n",
    "    print('Bad review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e435307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB().fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cc8b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = nb_model.predict(test_vectors)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bf55a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1072\n",
      "           1       0.76      0.78      0.77      1061\n",
      "\n",
      "    accuracy                           0.77      2133\n",
      "   macro avg       0.77      0.77      0.77      2133\n",
      "weighted avg       0.77      0.77      0.77      2133\n",
      "\n",
      "[[811 261]\n",
      " [236 825]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(test_data['sentiment'],all_predictions))\n",
    "print(confusion_matrix(test_data['sentiment'],all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c1d608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good review\n"
     ]
    }
   ],
   "source": [
    "data = ['Average movie']\n",
    "vector = vectorizer.transform(data).toarray()\n",
    "prediction = nb_model.predict(vector)\n",
    "\n",
    "\n",
    "if(prediction[0]==1):\n",
    "    print('Good review')\n",
    "else:\n",
    "    print('Bad review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4aaae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a3835a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_DT = classifier.predict(test_vectors)\n",
    "y_pred_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cbb110e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[690, 382],\n",
       "       [412, 649]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_DT = confusion_matrix(test_data['sentiment'],y_pred_DT)\n",
    "cm_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31379dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1072\n",
      "           1       0.63      0.61      0.62      1061\n",
      "\n",
      "    accuracy                           0.63      2133\n",
      "   macro avg       0.63      0.63      0.63      2133\n",
      "weighted avg       0.63      0.63      0.63      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['sentiment'],y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0af3d384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_rf = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
    "classifier_rf.fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b02b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[794, 278],\n",
       "       [371, 690]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_RF = classifier_rf.predict(test_vectors)\n",
    "cm_RF = confusion_matrix(test_data['sentiment'], y_pred_RF)\n",
    "cm_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f1d609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71      1072\n",
      "           1       0.71      0.65      0.68      1061\n",
      "\n",
      "    accuracy                           0.70      2133\n",
      "   macro avg       0.70      0.70      0.70      2133\n",
      "weighted avg       0.70      0.70      0.70      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['sentiment'],y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28dbdfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters using grid search: \n",
      " {'bootstrap': False, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto'}\n",
      "Time taken in grid search:  774.50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "fit_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "np.random.seed(42)\n",
    "start = time.time()\n",
    "\n",
    "param_dist = {'max_depth': [2, 3, 4],\n",
    "              'bootstrap': [True, False],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "cv_rf = GridSearchCV(fit_rf, cv = 10,\n",
    "                     param_grid=param_dist, \n",
    "                     n_jobs = 3)\n",
    "cv_rf.fit(train_vectors,train_data['sentiment'])\n",
    "print('Best Parameters using grid search: \\n', cv_rf.best_params_)\n",
    "end = time.time()\n",
    "print('Time taken in grid search: {0: .2f}'.format(end - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2324ace3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=15, oob_score=True,\n",
       "                       random_state=42, warm_start=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_rf.set_params(criterion = 'gini',\n",
    "                  max_features = 'auto', \n",
    "                  max_depth = 4, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b0fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:541: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/Adit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  decision = (predictions[k] /\n"
     ]
    }
   ],
   "source": [
    "fit_rf.set_params(warm_start=True, \n",
    "                  oob_score=True)\n",
    "\n",
    "min_estimators = 15\n",
    "max_estimators = 1000\n",
    "\n",
    "error_rate = {}\n",
    "\n",
    "for i in range(min_estimators, max_estimators + 1):\n",
    "    fit_rf.set_params(n_estimators=i)\n",
    "    fit_rf.fit(train_vectors,train_data['sentiment'])\n",
    "\n",
    "    oob_error = 1 - fit_rf.oob_score_\n",
    "    error_rate[i] = oob_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_series = pd.Series(error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax.set_facecolor('#fafafa')\n",
    "\n",
    "oob_series.plot(kind='line',color = 'red')\n",
    "plt.axhline(0.055, color='#875FDB',linestyle='--')\n",
    "plt.axhline(0.05, color='#875FDB',linestyle='--')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('OOB Error Rate')\n",
    "plt.title('OOB Error Rate Across various Forest sizes \\n(From 15 to 1000 trees)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6763a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6886d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "334b7d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV 2/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV 3/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   9.0s\n",
      "[CV 4/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   9.9s\n",
      "[CV 5/5] END ...................C=0.1, gamma=0.1, kernel=rbf; total time=   8.3s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.1s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.0s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.1s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.5s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.01, kernel=rbf; total time=   9.2s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   9.1s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.1s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   7.7s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.8s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.001, kernel=rbf; total time=   8.2s\n",
      "[CV 1/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV 2/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   7.2s\n",
      "[CV 3/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   7.5s\n",
      "[CV 4/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV 5/5] END .....................C=1, gamma=0.1, kernel=rbf; total time=   7.4s\n",
      "[CV 1/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV 2/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   8.0s\n",
      "[CV 3/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   9.7s\n",
      "[CV 4/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=  10.5s\n",
      "[CV 5/5] END ....................C=1, gamma=0.01, kernel=rbf; total time=   7.0s\n",
      "[CV 1/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   7.3s\n",
      "[CV 2/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 3/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   6.8s\n",
      "[CV 4/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 5/5] END ...................C=1, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 1/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   7.2s\n",
      "[CV 2/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   6.7s\n",
      "[CV 3/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   6.7s\n",
      "[CV 4/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   7.9s\n",
      "[CV 5/5] END ....................C=10, gamma=0.1, kernel=rbf; total time=   6.7s\n",
      "[CV 1/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   6.5s\n",
      "[CV 2/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   6.4s\n",
      "[CV 3/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   8.5s\n",
      "[CV 4/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   6.8s\n",
      "[CV 5/5] END ...................C=10, gamma=0.01, kernel=rbf; total time=   7.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   6.9s\n",
      "[CV 2/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 3/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   6.9s\n",
      "[CV 4/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 5/5] END ..................C=10, gamma=0.001, kernel=rbf; total time=   7.0s\n",
      "[CV 1/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   7.0s\n",
      "[CV 2/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   8.1s\n",
      "[CV 3/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   7.2s\n",
      "[CV 4/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   7.1s\n",
      "[CV 5/5] END ...................C=100, gamma=0.1, kernel=rbf; total time=   7.3s\n",
      "[CV 1/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   7.7s\n",
      "[CV 2/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   7.7s\n",
      "[CV 3/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   7.4s\n",
      "[CV 4/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   7.4s\n",
      "[CV 5/5] END ..................C=100, gamma=0.01, kernel=rbf; total time=   7.6s\n",
      "[CV 1/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   6.3s\n",
      "[CV 2/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   6.5s\n",
      "[CV 3/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   6.4s\n",
      "[CV 4/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   6.3s\n",
      "[CV 5/5] END .................C=100, gamma=0.001, kernel=rbf; total time=   6.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'gamma': [0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(svm.SVC(), param_grid,verbose = 3)\n",
    "  \n",
    "grid.fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94614f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ec885d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = svm.SVC(C=10,gamma=0.1,kernel='rbf')\n",
    "svc.fit(train_vectors,train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc3a56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tuned_pred = svc.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5cd58a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1072\n",
      "           1       0.74      0.76      0.75      1061\n",
      "\n",
      "    accuracy                           0.75      2133\n",
      "   macro avg       0.75      0.75      0.75      2133\n",
      "weighted avg       0.75      0.75      0.75      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_data['sentiment'],svm_tuned_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, svm_tuned_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
